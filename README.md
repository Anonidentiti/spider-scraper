## spider-scraper:
 Tool to scrape all directories in a website but still on Beta
 
## Installation:
1. git clone https://github.com/Anonidentiti/spider-scarper.git
2. Install the required dependencies using 
3. pip3 install -r requirements.txt
   or 
   pip install -r requirements.txt
   (might depend on version)
   
## HOW TO USE SPIDER-SCRAPER:

 
usage: spider.py [-h] -u URL [-s]

Web scraping tool

Options:
  -h, --help : show this help message and exit
  
  -u URL, --url : URL  URL to scrape

  -s, --save : Saves output to a .txt file
  
  
Optional arguments:
- `-A, --aggressive`: Number of threads for aggressive scan (default: 4)

## Contributing

Contributions are welcome! If you find any bugs or have suggestions for improvement, please open an issue or submit a pull request.

## License

This project is licensed under the MIT License.
